# Step 1.1: Preprocess Images
import tensorflow as tf
import numpy as np

image_size = (224, 224)  # Resize images to 224x224 for ViT

def preprocess_image(image_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_image(image, channels=3)
    image = tf.image.resize(image, image_size)
    image = image / 255.0  # Normalize to [0,1]
    return image

# Preprocess all images
preprocessed_images = [preprocess_image(path) for path in all_image_files]


# Step 1.2: Convert Labels to Integers
# Assuming 'labels' is a list of labels corresponding to 'all_image_files'
labels = [label_map[file] for file in all_image_files]  # Define 'label_map' as needed

label_to_index = {label: index for index, label in enumerate(set(labels))}
integer_labels = np.array([label_to_index[label] for label in labels])


# Step 1.3: Split Data into Train, Validation, Test Sets
from sklearn.model_selection import train_test_split

train_images, temp_images, train_labels, temp_labels = train_test_split(preprocessed_images, integer_labels, test_size=0.3, random_state=42)
val_images, test_images, val_labels, test_labels = train_test_split(temp_images, temp_labels, test_size=0.5, random_state=42)

# Convert lists to numpy arrays
train_images = np.array(train_images)
val_images = np.array(val_images)
test_images = np.array(test_images)


#Step 2: Implement Vision Transformer (ViT) Model

# Step 2.1: Define and Compile ViT Model
import tensorflow_hub as hub
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Flatten

vit_model_url = "https://tfhub.dev/google/vit_base_patch16_224/1"
vit_layer = hub.KerasLayer(vit_model_url)

def create_vit_model():
    inputs = Input(shape=(224, 224, 3))
    vit_features = vit_layer(inputs)
    x = Flatten()(vit_features)
    x = Dense(128, activation='relu')(x)
    outputs = Dense(len(label_to_index), activation='softmax')(x)  # Adjust output layer to the number of classes
    model = Model(inputs=inputs, outputs=outputs)
    return model

vit_model = create_vit_model()
vit_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])


# Step 2.2: Train the Model
history = vit_model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))

# Save the trained model
vit_model.save('vit_model.h5')


Step 3: Implement Explainable AI Techniques


# Step 3.1: SHAP for Feature Importance
!pip install shap
import shap

# Create SHAP explainer
explainer = shap.KernelExplainer(vit_model.predict, train_images[:100])  # Use a subset for background data

# Explain a single prediction
shap_values = explainer.shap_values(val_images[:1])
# Visualize
shap.image_plot(shap_values, val_images[:1])


# Step 3.2: Grad-CAM for Visual Explanations
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model

def get_gradcam_heatmap(model, img_array, last_conv_layer_name, pred_index=None):
    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]
    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., np.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)
    return heatmap

def display_gradcam(img_path, heatmap):
    img = tf.keras.preprocessing.image.load_img(img_path)
    img = tf.keras.preprocessing.image.img_to_array(img)
    heatmap = np.uint8(255 * heatmap)
    jet = plt.get_cmap("jet")
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]
    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)
    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))
    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)
    superimposed_img = jet_heatmap * 0.4 + img
    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)
    plt.imshow(superimposed_img)

# Generate and display heatmap
heatmap = get_gradcam_heatmap(vit_model, np.expand_dims(val_images[0], axis=0), "last_conv_layer_name")
display_gradcam(all_image_files[0], heatmap)


# Step 3.3: LIME for Local Explanations
!pip install lime
import lime
import lime.lime_image

explainer = lime.lime_image.LimeImageExplainer()

def explain_image(image_path):
    image = preprocess_image(image_path)
    explanation = explainer.explain_instance(np.array(image), vit_model.predict, top_labels=1, hide_color=0, num_samples=1000)
    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=10, hide_rest=False)
    plt.imshow(temp)
    plt.imshow(mask, alpha=0.5)
    plt.show()

# Explain image
explain_image(all_image_files[0])


Step 4: Model Evaluation


# Step 4.1: Evaluate Model Performance
from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix

# Predict and evaluate
predictions = vit_model.predict(val_images)
predicted_labels = np.argmax(predictions, axis=1)

# Calculate metrics
accuracy = accuracy_score(val_labels, predicted_labels)
f1 = f1_score(val_labels, predicted_labels, average='weighted')
precision = precision_score(val_labels, predicted_labels, average='weighted')
conf_matrix = confusion_matrix(val_labels, predicted_labels)

# Print metrics
print(f"Accuracy: {accuracy}")
print(f"F1 Score: {f1}")
print(f"Precision: {precision}")
print(f"Confusion Matrix:\n{conf_matrix}")


# Step 4.2: Save Evaluation Metrics to CSV
import pandas as pd

results = {
    'Accuracy': [accuracy],
    'F1 Score': [f1],
    'Precision': [precision],
    'Confusion Matrix': [conf_matrix.tolist()]  # Convert to list for CSV compatibility
}

results_df = pd.DataFrame(results)
results_df.to_csv('evaluation_metrics.csv', index=False)


Step 5: Prediction Function


# Step 5.1: Create Prediction Function
def predict_class(image_path):
    image = preprocess_image(image_path)
    image = np.expand_dims(image, axis=0)  # Add batch dimension
    prediction = vit_model.predict(image)
    predicted_label = np.argmax(prediction, axis=1)[0]
    return list(label_to_index.keys())[predicted_label]

# Example usage
predicted_class = predict_class('/path/to/image.jpg')
print(f"Predicted class: {predicted_class}")



